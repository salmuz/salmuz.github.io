<!DOCTYPE html>
<html lang="zxx" class="no-js">
<head>
    <!-- Mobile Specific Meta -->
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- Favicon-->
    <link rel="shortcut icon" href="img/fav.png">
    <!-- Author Meta -->
    <meta name="author" content="colorlib">
    <!-- Meta Description -->
    <meta name="description" content="">
    <!-- Meta Keyword -->
    <meta name="keywords" content="">
    <!-- meta character set -->
    <meta charset="UTF-8">
    <!-- Site Title -->
    <title>Personal</title>

    <link href="https://fonts.googleapis.com/css?family=Poppins:100,200,400,300,500,600,700" rel="stylesheet">
    <!--
    CSS
    ============================================= -->
    <link rel="stylesheet" href="css/linearicons.css">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link rel="stylesheet" href="css/bootstrap.css">
    <link rel="stylesheet" href="css/magnific-popup.css">
    <link rel="stylesheet" href="css/nice-select.css">
    <link rel="stylesheet" href="css/animate.min.css">
    <link rel="stylesheet" href="css/owl.carousel.css">
    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/main.css">
    <style type="text/css">
        ol, ul {
            margin: 0;
            padding: 0;
            list-style: none;
        }

        ol {
            counter-reset: list;
        }

        ol > li {
            list-style: none;
            position: relative;
            margin-left: 2%;
            margin-bottom: 5px
        }

        ol > li:before {
            content: "[" counter(list) "]";
            counter-increment: list;
            left: -40px;
            padding-right: 4px;
            text-align: right;
            width: 40px;
            font-weight: 400;
            color: #8490ff;
        }
    </style>
</head>
<body>
<header id="header">
    <div class="container main-menu">
        <div class="row align-items-center justify-content-between d-flex">
            <div id="logo">
                <a href="index.html">
                    <img src="img/salmuz.png"
                         style="height: 51px;
							 		margin-bottom: -15px;
							 		margin-top: -15px;"
                         alt="" title=""/>
                </a>
            </div>
            <nav id="nav-menu-container">
                <ul class="nav-menu">
                    <li><a href="index.html">Home</a></li>
                    <li><a href="about.html">About</a></li>
                    <li><a href="papers.html">Publications</a></li>
                    <li><a href="teaching.html">Teaching</a></li>
                    <li><a href="comingsoon.html">Software</a></li>
                    <li class="menu-has-children"><a href="#">Blog</a>
                        <ul>
                            <li><a href="comingsoon.html">Spanish</a></li>
                            <li><a href="comingsoon.html">English</a></li>
                        </ul>
                    </li>
                    <li><a href="contact.html">Contact</a></li>
                </ul>
            </nav><!-- #nav-menu-container -->
        </div>
    </div>
</header>
<!-- #header -->
<!-- start banner Area -->
<section class="about-banner">
    <div class="container">
        <div class="row d-flex align-items-center justify-content-center">
            <div class="about-content col-lg-11">
                <h2 class="text-white text-left">
                    Publications
                </h2>
                <p class="text-white link-nav text-left">
                    Below, I present my publications and other current research works. I also put the information
                    concerning them as well as consultation links.
                </p>
            </div>
        </div>
    </div>
</section>
<!-- End banner Area -->
<!-- Start services Area -->
<!-- template to put a new paper -->
<!--<li style="margin-left: 2%; margin-bottom: 2px">-->
<!--    <a class="showCorsur abstract"-->
<!--       data-toggle="collapse"-->
<!--       style="color:black;"-->
<!--       href="#xxx">-->
<!--        xxx-authors-xxx-->
<!--        <b>xxx-title-xx.</b>-->
<!--        <em>xxx-conference--xxx</em>-->
<!--        Novembre 2018.-->
<!--    </a>-->
<!--    <a href="xxx" target="_blank">[PDF]</a>-->
<!--    <a href="xxx" target="_blank">[Slider]</a>-->
<!--    <a href="xxx" target="_blank">[Link]</a>-->
<!--    <div class="collapse multi-collapse" id="xxx">-->
<!--        <p class="text-justify"><b>Abstract: </b>-->
<!--        </p>-->
<!--    </div>-->
<!--</li>-->
<section class="home-about-area section-gap">
    <div class="container">
        <div class="row d-flex justify-content-center">
            <div class="menu-content  col-lg-11 col-md-6">
                <div class="title text-left" style="margin-top: 20px">
                    <h3 class="mb-10">Current works (tentative titles)</h3>
                    <ol>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#rloss">
                                Y.C. Carranza Alarcón, Vu-Linh Nguyen
                                <b>Distributionally robust, skeptical inferences in multi-label ranking</b>
                                2022.
                                <b style="color:orangered">[in preparation.]</b>
                            </a>
                            <!--                            <a href="xxx" target="_blank">[PDF]</a>-->
                            <!--                            <a href="xxx" target="_blank">[Slider]</a>-->
                            <!--                            <a href="xxx" target="_blank">[Link]</a>-->
                            <div class="collapse multi-collapse" id="rloss">
                                <p class="text-justify"><b>Abstract: </b>
                                    In this works, we seek to reduce the number of comparisons of the maximality
                                    criterion (as well as others criterion decisions, namely, interval dominance,
                                    E-admissibility, and so on) on structured loss function (e.g. ranking loss).
                                </p>
                            </div>
                        </li>
                        <li>
                            <a class="showCorsur abstract"
                                data-toggle="collapse"
                                style="color:black;"
                                href="#axiomatic">
                                Y.C. Carranza Alarcón.
                                <b> Technical Report: Description of optimisation problems used to 
                                    implement Python svm-label-ranking library.</b>
                                <!-- <b>An axiomatic approach on a partially order space in multi-label problem and -->
                                <!-- imprecise probabilities</b> -->
                                2022.
                                <b style="color:orangered">[in preparation.]</b>
                                <a href="https://pypi.org/project/svm-label-ranking/" target="_blank">[Source Code]</a>
                            </a>
<!--                            <a href="xxx" target="_blank">[PDF]</a>-->
<!--                            <a href="xxx" target="_blank">[Slider]</a>-->
                           
<!--                            <div class="collapse multi-collapse" id="nonlineal">-->
<!--                                <p class="text-justify"><b>Abstract: </b>-->
<!--                                </p>-->
                                <!-- </div> -->
                        </li>
                    </ol>
                </div>
                <div class="title text-left" style="margin-top: 20px">
                    <h3 class="mb-10">Journals</h3>
                    <ol>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#pattern2020">
                                Y.C. Carranza Alarcón, Sébastien Destercke.
                                <b>Imprecise Gaussian Discriminant Classification.</b>
                                <em>Pattern Recognition, Vol. 112,</em>
                                October 2020.
                                <a href="https://www.sciencedirect.com/science/article/pii/S0031320320305422"
                                   target="_blank">[PDF]</a>
                            </a>
                            <div class="collapse multi-collapse" id="pattern2020">
                                <p class="text-justify"><b>Abstract: </b>
                                    Gaussian discriminant analysis is a popular classification model, that in the
                                    precise
                                    case can produce unreliable predictions in case of high uncertainty (e.g., due to
                                    scarce or noisy data). While imprecise probability theory offers a nice theoretical
                                    framework to solve such issues, it has not been yet applied to Gaussian discriminant
                                    analysis. This work remedies this, by proposing a new Gaussian discriminant analysis
                                    based on robust Bayesian analysis and near-ignorance priors. The model delivers
                                    cautious
                                    predictions, in form of set-valued class, in case of limited or imperfect available
                                    information. We present and discuss results of experimentation on real and synthetic
                                    datasets, where for this latter we corrupt the test instance to see how our approach
                                    reacts to non i.i.d. samples. Experiments show that including an imprecise component
                                    in the Gaussian discriminant analysis produces reasonably cautious predictions,
                                    and that set-valued predictions correspond to instances for which the precise model
                                    performs poorly.
                                </p>
                            </div>
                        </li>

                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#arxiv2205.00662">
                                Y.C. Carranza Alarcón, Sébastien Destercke.
                                <b>Skeptical binary inferences in multi-label problems with sets of probabilities.</b>
                               <em>10.48550/ARXIV.2205.00662,</em>
                               May 2022.
                               <a href="https://arxiv.org/pdf/2205.00662.pdf" target="_blank">[PDF]</a>
                            </a>
                           <div class="collapse multi-collapse" id="arxiv2205.00662">
                               <p class="text-justify"><b>Abstract: </b>
                                In this paper, we consider the problem of making distributionally robust, skeptical inferences for the multi-label problem, or more generally for Boolean vectors. By distributionally robust, we mean that we consider a set of possible probability distributions, and by skeptical we understand that we consider as valid only those inferences that are true for every distribution within this set. Such inferences will provide partial predictions whenever the considered set is sufficiently big. We study in particular the Hamming loss case, a common loss function in multi-label problems, showing how skeptical inferences can be made in this setting. Our experimental results are organised in three sections; (1) the first one indicates the gain computational obtained from our theoretical results by using synthetical data sets, (2) the second one indicates that our approaches produce relevant cautiousness on those hard-to-predict instances where its precise counterpart fails, and (3) the last one demonstrates experimentally how our approach copes with imperfect information (generated by a downsampling procedure) better than the partial abstention [31] and the rejection rules.
                               </p>
                            </div>
                        </li>
                    </ol>
                </div>
                <div class="title text-left" style="margin-top: 20px">
                    <h3 class="mb-10">International conferences</h3>
                    <ol>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#ecsqaru21">
                                Y.C. Carranza Alarcón, Sébastien Destercke.
                                <b>Multi-label chaining using naive credal classifier.</b>
                                <em>The Sixteenth European Conference on Symbolic and Quantitative Approaches
                                    with Uncertainty (ECSQARU).</em>
                                Sept 2021.
<!--                                <b style="color:orangered">[accepted.]</b>-->
                            </a>
<!--                            <div style="position: absolute;margin-top: -48px;margin-left:75%;">-->
<!--                                <img src="img/coming_soon.png" width="52">-->
<!--                            </div>-->
                            <a href="https://arxiv.org/abs/2107.07443" target="_blank">[PDF]</a>
                            <a href="works/ECSQARU21_sliders.pdf" target="_blank">[Slider]</a>
                            <div class="collapse multi-collapse" id="ecsqaru21">
                                <p class="text-justify"><b>Abstract: </b>
                                    We present two different strategies to extend the classical multi-label chaining
                                    approach to handle imprecise probability estimates. These estimates use convex
                                    sets of distributions (or credal sets) in order to describe our uncertainty rather
                                    than a precise one. The main reasons one could have for using such estimations are
                                    (1) to make cautious predictions (or no decision at all) when a high uncertainty
                                    is detected in the chaining and (2) to make better precise predictions by avoiding
                                    biases caused in early decisions in the chaining. We adapt both strategies to the
                                    case of the naive credal classifier, showing that this adaptations are
                                    computationally efficient. Our experimental results on missing labels,
                                    which investigate how reliable these predictions are in both approaches,
                                    indicate that our approaches produce relevant cautiousness on those hard-to-predict
                                    instances where the precise models fail.
                                </p>
                            </div>
                        </li>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#isipta2021">
                                Y.C. Carranza Alarcón, Sébastien Destercke.
                                <b>Distributionally robust, skeptical binary inferences in multi-label problems.</b>
                                <em>Proceedings of Machine Learning Research, Volume 147 (ISIPTA2021).</em>
                                July 2021.
                            </a>
                            <a href="https://leo.ugr.es/isipta21/pmlr/carranzaalarcon21.pdf"
                               target="_blank">[PDF]</a>
                            <a href="works/ISIPTA21/ISIPTA_2021_slider.pdf" target="_blank">[Slider]</a>
                            <a href="works/ISIPTA21/ISIPTA_2021_poster.pdf" target="_blank">[Poster]</a>
                            <div class="collapse multi-collapse" id="isipta2021">
                                <p class="text-justify"><b>Abstract: </b>
                                    In this paper, we consider the problem of making distributionally robust,
                                    skeptical inferences for the multi-label problem, or more generally for Boolean
                                    vectors. By distributionally robust, we mean that we consider sets of probability
                                    distributions, and by skeptical we understand that we consider as valid only those
                                    inferences that are true for every distribution within this set. Such inferences
                                    will provide partial predictions whenever the considered set is sufficiently big.
                                    We study in particular the  Hamming loss case, a common loss function in multi-label
                                    problems, showing how skeptical inferences can be made in this setting. We also
                                    perform some experiments demonstrating the interest of our results.
                                </p>
                            </div>
                        </li>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#ipmu2020">
                                Y.C. Carranza-Alarcón, Soundouss Messoudi, Sébastien Destercke
                                <b>Cautious label-wise ranking with constraint satisfaction.</b>
                                <em>18th International Conference, IPMU 2020.</em>
                                June 2020
                            </a>
                            <a href="https://link.springer.com/chapter/10.1007/978-3-030-50143-3_8" target="_blank">[PDF]</a>
                            <a href="works/IPMU_2020_slider.pdf" target="_blank">[Slider]</a>
                            <a href="works/bib/10.1007_978-3-030-50143-3_8.bib" target="_blank">[BibTeX]</a>
                            <div class="collapse multi-collapse" id="ipmu2020">
                                <p class="text-justify"><b>Abstract: </b>
                                    Ranking problems are difficult to solve due to their combinatorial nature.
                                    One way to solve this issue is to adopt a decomposition scheme, splitting
                                    the initial difficult problem in many simpler problems. The predictions
                                    obtained from these simplified settings must then be combined into one
                                    single output, possibly resolving inconsistencies between the outputs.
                                    In this paper, we consider such an approach for the label ranking problem,
                                    where in addition we allow the predictive model to produce cautious inferences
                                    in the form of sets of rankings when it lacks information to produce reliable,
                                    precise predictions. More specifically, we propose to combine a rank-wise
                                    decomposition, in which every sub-problem becomes an ordinal classification one,
                                    with a constraint satisfaction problem (CSP) approach to verify the consistency of
                                    the predictions. Our experimental results indicate that our approach produces
                                    predictions with appropriately balanced reliability and precision, while
                                    remaining competitive with classical, precise approaches.
                                </p>
                            </div>
                        </li>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#isipta2019">
                                Y.C. Carranza-Alarcón, Sébastien Destercke.
                                <b>Imprecise Gaussian Discriminant Classification.</b>
                                <em>Proceedings of Machine Learning Research, Volume 103 (ISIPTA2019).</em>
                                July 2019.
                            </a>
                            <a href="http://proceedings.mlr.press/v103/carranza-alarcon19a/carranza-alarcon19a.pdf"
                               target="_blank">[PDF]</a>
                            <a href="works/ISIPTA_2019_slider.pdf" target="_blank">[Slider]</a>
                            <a href="works/ISIPTA_2019_poster.pdf" target="_blank">[Poster]</a>
                            <div class="collapse multi-collapse" id="isipta2019">
                                <p class="text-justify"><b>Abstract: </b>
                                    Gaussian discriminant analysis is a popular classification
                                    model, that in the precise case can produce unreliable
                                    predictions in case of high uncertainty. While imprecise probability
                                    theory offer a nice theoretical framework to solve this issue, it has not
                                    been yet applied to Gaussian discriminant analysis. This work remedies this,
                                    by proposing a new Gaussian discriminant analysis based on robust Bayesian
                                    analysis and near-ignorance priors. The model delivers cautious predictions,
                                    in form of set-valued class, in case of limited or imperfect available information.
                                    Experiments show that including an imprecise component in the
                                    Gaussian discriminant analysis produces reasonably cautious predictions,
                                    in the sense that the number of set-valued predictions is not too high, and that
                                    those predictions correspond to hard-to-classify instances, that is instances
                                    for which the precise classifier accuracy drops.
                                </p>
                            </div>
                        </li>

                    </ol>
                </div>
                <div class="title text-left" style="margin-top: 20px">
                    <h3 class="mb-10">National (French) Conference</h3>
                    <ol>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#lfa2020">
                                Y.C. Carranza-Alarcón, Soundouss Messoudi, Sébastien Destercke
                                <b>Apprentissage de rangements prudent avec satisfaction de contraintes.</b>
                                <em>29èmes Rencontres francophones sur la Logique Floue et ses Applications.</em>
                                October 2020.
                            </a>
                            <!--                            <div style="position: absolute;margin-top: -43px;margin-left:45%;">-->
                            <!--                                <img src="img/coming_soon.png" width="52">-->
                            <!--                            </div>-->
                            <a href="works/LFA2020/cautious_ranking_fr.pdf" target="_blank">[PDF]</a>
                            <a href="works/LFA2020/LFA20_conference.pdf" target="_blank">[Slider]</a>
                            <a href="https://www.cepadues.com/auteur/carranza-alarcon-yonatan-carlos/1610.html"
                               target="_blank">[Editor]</a>
                            <div class="collapse multi-collapse" id="lfa2020">
                                <p class="text-justify"><b>Abstract: </b>
                                    Apprendre à prédire des rangements d’étiquettes est un problème difficile, en
                                    raison
                                    de leur nature combinatoire. Une façon de le contourner est de diviser le problème
                                    initial en plusieurs sous-problèmes plus simples. Les prédictions obtenues à
                                    partir
                                    de ces sous-problèmes simplifiés doivent ensuite être combinées en une seule
                                    sortie,
                                    résolvant les éventuelles incohérences entre les sorties. Dans ce travail, nous
                                    adoptons une telle approche en permettant aux sous-problèmes de produire des
                                    inférences prudentes sous la forme d’ensembles de rangs lorsque l’incertitude
                                    attachée aux données produit des prédictions peu fiables. Plus précisément,
                                    nous
                                    proposons de combiner une décomposition par rang, dans laquelle chaque
                                    sous-problème devient une régression ordinale prudente, avec les problème de
                                    satisfaction de contraintes (CSP) pour vérifier la cohérence des prédictions. Nos
                                    résultats expérimentaux indiquent que notre approche produit des prédictions avec
                                    une fiabilité et une précision équilibrée, tout en restant compétitive avec les
                                    approches classiques
                                </p>
                            </div>
                        </li>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#lfa2018">
                                Y.C. Carranza-Alarcón, Sébastien Destercke.
                                <b>Analyse discriminante imprécise basée sur l'inférence bayésienne robuste.</b>
                                <em>27èmes Rencontres francophones sur la Logique Floue et ses Applications.</em>
                                November 2018.
                            </a>
                            <a href="works/LFA2018/imprecise_qda_fr.pdf" target="_blank">[PDF]</a>
                            <a href="works/LFA2018/LFA_conference.pdf" target="_blank">[Slider]</a>
                            <a href="https://www.cepadues.com/auteur/carranza-alarcon-yonatan-carlos/1610.html"
                               target="_blank">[Editor]</a>
                            <div class="collapse multi-collapse" id="lfa2018">
                                <p class="text-justify"><b>Abstract: </b>
                                    L’objectif de cet article est de proposer une nouvelle approche de
                                    classification prudente basée sur l’inférence Bayésienne robuste et
                                    l’analyse discriminante linéaire. Cette modélisation est conçue pour
                                    prendre en compte, dans ses inférences a posteriori, le manque d’information
                                    lié aux données. Le principe de cette approche est d’utiliser un ensemble
                                    de distributions a priori pour modéli- ser l’ignorance initiale, plutôt qu’une
                                    seule distribution (souvent dite “non-informative”) qui peut fortement influencer
                                    les résultats en cas de faible quantité de données. Des premières expériences
                                    montrent que l’ajout d’impré- cision permet d’être prudent en cas de doute sans
                                    pour autant diminuer la qualité du modèle, tout en gardant un temps de calcul
                                    raisonnable.
                                </p>
                            </div>
                        </li>
                    </ol>
                </div>
                <div class="title text-left" style="margin-top: 20px">
                    <h3 class="mb-10">Workshops</h3>
                    <ol>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#wuml2020">
                                Y.C. Carranza Alarcón, Sébastien Destercke
                                <b>A first glance at multi-label chaining using imprecise probabilities.</b>
                                <em>Workshop on Uncertainty in Machine Learning (WUML).</em>
                                September 2020.
                            </a>
                            <a href="works/WUML_2020.pdf" target="_blank">[PDF]</a>
                            <a href="works/WUML_2020_slider.pdf" target="_blank">[Slider]</a>
                            <div class="collapse multi-collapse" id="wuml2020">
                                <p class="text-justify"><b>Abstract: </b>
                                    In this paper, we present two different ways to extend the classical multi-label
                                    chaining approach to handle imprecise probability estimates. These estimates use
                                    convex sets of distributions (or credal sets) in order to describe our uncertainty
                                    rather than a precise one. The main reasons one could have for using such estimates
                                    are (1) to make cautious predictions (or no decision at all) when a high uncertainty
                                    is detected in the chaining and (2) to make better precise predictions by avoiding
                                    biases caused in early decisions in the chaining. We perform experiments on
                                    missing and noisy labels to investigate how accurate and how precise these
                                    predictions are in both approaches. Our experimental results indicate that while our
                                    approach produce relevant cautiousness (i.e., forget predictions likely to be
                                    erroneous),
                                    results regarding possible bias correction using a minimax approach are less
                                    encouraging,
                                    except when high adversarial noise affect the labels, in which case our approach
                                    outperform its precise counterpart.
                                </p>
                            </div>
                        </li>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#da2pl2018">
                                Sébastien Destercke, Y.C. Carranza Alarcón
                                <b>Some results on cautious label-wise ranking with constraint satisfactions.</b>
                                <em>From Multiple Criteria Decision Aid to Preference Learning (DA2PL).</em>
                                November 2018.
                            </a>
                            <a href="works/DA2PL_2018.pdf" target="_blank">[PDF]</a>
                            <a href="works/DA2PL_2018_slider.pdf" target="_blank">[Slider]</a>
                            <div class="collapse multi-collapse" id="da2pl2018">
                                <p class="text-justify"><b>Abstract: </b>
                                    Ranking problems are usually difficult to solve, due to their combinatorial
                                    nature. One way to circumvent this issue is to adopt a decomposition scheme,
                                    in which the initial difficult problem is split into a set of simpler problems.
                                    The predictions obtained from these simplified settings must then be combined
                                    into one single output, possibly resolving observed inconsistencies between
                                    the outputs. In this paper, we consider such an approach for the label
                                    ranking problem, where in addition we allow the predictive model to produce
                                    cautious inferences in the form of sets of rankings when it lacks information
                                    to produce reliable, precise predictions. More particularly, we propose to
                                    combine a rank-wise decomposition, in which every sub-problem becomes an
                                    ordinal classification one, with a constraint satisfaction problem (CSP)
                                    approach to verify the overall consistency of the predictions.
                                </p>
                            </div>
                        </li>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#xxx">
                                Y.C. Carranza Alarcón, Sébastien Destercke
                                <b>Some results on linear imprecise discriminant analysis</b>
                                <em>11th Workshop on Principles and Methods of Statistical
                                    Inference with Interval Probability (WPMSIIP)
                                </em>
                                July 2018.
                            </a>
                            <a href="works/WPMSIIP_2018_slider.pdf" target="_blank">[Slider]</a>
                            <a href="http://www.sipta.org/ssipta18/ScheduleWPMSIIP.html" target="_blank">[Workshop]</a>
                            <div class="collapse multi-collapse" id="xxx">
                                <p class="text-justify"><b>Abstract: </b>
                                    (Coming soon)
                                </p>
                            </div>
                        </li>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#sixthR">
                                Y.C. Carranza-Alarcon, B. Liquet, L Baschet et S. Marque
                                <b>Evaluation of the Heemod package and implementation of a
                                    Shiny synthesis table for cost-effectiveness analysis</b>
                                <em>Sixth Rencontres R</em>
                                June 2017.
                            </a>
                            <a href="works/RencontresR_2017.pdf" target="_blank">[PDF]</a>
                            <a href="works/RencontresR_2017_slider.pdf" target="_blank">[Slider]</a>
                            <a href="https://github.com/salmuz/WAHEco" target="_blank">[Software]</a>
                            <div class="collapse multi-collapse" id="sixthR">
                                <p class="text-justify"><b>Abstract: </b>
                                </p>
                            </div>
                        </li>
                    </ol>
                </div>
                <div class="title text-left" style="margin-top: 20px">
                    <h3 class="mb-10">PhD dissertation</h3>
                    <ol>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#PhdDissertation">
                                Y.C. Carranza-Alarcon,
                                <b>Distributionally robust, skeptical inferences in supervised classification
                                    using imprecise probabilities.</b>
                                <i>PhD Thesis at University of Technology of Compiègne.</i>
                                Supervised by Sébastien Destercke. December 2020
                            </a>
                            <a href="works/PhD_Thesis_YCCA_final_version.pdf" target="_blank">[PDF]</a>
                            <a href="works/PhD_defense.pdf" target="_blank">[Slider]</a>
                        </li>
                    </ol>

                </div>
                <div class="title text-left" style="margin-top: 20px">
                    <h3 class="mb-10">Master's works</h3>
                    <ol>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#BIOSTAT17">
                                Y.C. Carranza-Alarcon, supervised by Benoit LIQUET and Louise BASCHET.
                                <b>Health-Economic modeling using Markov model.</b>
                                September 2017.
                            </a>
                            <!--                            <a href="xxx" target="_blank">[PDF]</a>-->
                            <a href="works/BIOSTAT_2017_slider.pdf" target="_blank">[Slider]</a>
                            <div class="collapse multi-collapse" id="BIOSTAT17">
                                <p class="text-justify"><b>Abstract: </b>
                                    Markov models are powerful statistical tools for analyzing and assessing the cost
                                    and health consequences of new health-care interventions (i.e., a health-economic
                                    evaluation). These are often used by health economists who have tried to implement
                                    them using tools that are simple to use but not necessarily the most adapted
                                    or scalable.
                                    Thus, the search for the tools to implement this kind of model has become a major
                                    challenge because the use of spreadsheets (of the Microsoft Office Excel type) is
                                    a source of errors and limits the traceability and the quality control, in addition,
                                    they are not specialized in solving statistical problems.
                                    Capionis, a biostatistics consulting firm, is now seeking to improve their
                                    implementation process based on tools that can optimize and/or automate a subprocess
                                    of the global process (e.g. automated graphics reporting Sensitivity analysis).
                                    For this, the Heemod package of R is an alternative which has seemed to us
                                    interesting. We have therefore focused to evaluate and analyze the package,
                                    implementing several real cases of health-economic evaluation, already developed
                                    and validated by the team of biostatistics at Capionis.
                                    Despite the novelty of the package and the difficulties encountered in reproducing
                                    health-economic results due to the missing characteristics, we have not found any
                                    problem with the accuracy of numerical results, but its flexibility to implement or
                                    migrate real cases is not satisfactory in contrast to the Microsoft Excel tool.
                                    Then, we can not pretend to judge the efficiency and efficiency of the Heemod
                                    package compared to Microsoft Excel, since it has been used for over 20 years
                                    unlike the package (around 1 year).
                                    In addition, we have also developed a “simple” web platform for the end user
                                    and/or the community. This platform uses Heemod package, and was fully implemented
                                    in R with Shiny.

                                </p>
                            </div>
                        </li>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#BIOSTAT16">
                                Y.C. Carranza Alarcón, supervised by Xavier BRY.
                                <b>Recherche de composante(s) explicative(s) par pénalisation.</b>
                                Novembre 2018.
                            </a>
                            <a href="works/BIOSTAT_2016.pdf" target="_blank">[PDF]</a>
                            <a href="works/BIOSTAT_2016_slider.pdf" target="_blank">[Slider]</a>
                            <div class="collapse multi-collapse" id="BIOSTAT16">
                                <p class="text-justify"><b>Abstract: (Coming soon)</b>
                                </p>
                            </div>
                        </li>
                        <li>
                            <a class="showCorsur abstract"
                               data-toggle="collapse"
                               style="color:black;"
                               href="#decol15">
                                Y.C. Carranza Alarcón, supervised by Maximilien SERVAJEAN
                                <b>Modélisation des usages utilisateurs pour le Crowdsourcing à grande échelle.</b>
                                June 2015.
                            </a>
                            <a href="works/DECOL_2015.pdf" target="_blank">[PDF]</a>
                            <a href="works/DECOL_2015_slider.pdf" target="_blank">[Slider]</a>
                            <!--                            <a href="xxx" target="_blank">[Link]</a>-->
                            <div class="collapse multi-collapse" id="decol15">
                                <p class="text-justify"><b>Abstract: </b>
                                    Nowadays, Crowdsoucing services are increasingly used in a variety of applications,
                                    because they allow to publish small tasks to be performed by a large group of
                                    networked people at low-cost.
                                    Those services are structured in processes, or stages, to ensure the quality of
                                    work,
                                    such as assignment of tasks, workers’ skills estimation and quality estimation.
                                    This study focused on deepening the quality estimation stage of Crowdsourcing by
                                    proposing a model of the users behaviors enabling us to evaluate state-of-the art
                                    Crowdsourcing solutions.
                                    Therefore, we used the Confusion Matrix to represent the knowledge of the user
                                    in a multi-class classification problem and then model four different user profiles
                                    (e.g. expert and amateur). These profiles follow a discrete probability distribution
                                    (e.g. logarithmic distribution ) and knowledge of the user will be generated from
                                    this distribution and Monte-Carlo Simulation.
                                    We also explored another horizon by analyzing the real data of the Tela-Botanica web
                                    site in order to extract realistic profiles.
                                    Thus, with the help of this model, we will perform a set of random simulations
                                    in order to validate our profiles and to evaluate two methods, or inferences, of
                                    Crowdsoucing solutions.
                                </p>
                            </div>
                        </li>
                    </ol>
                </div>
            </div>
        </div>
        <div class="row">
        </div>
    </div>
</section>
<!-- End services Area -->


<!-- start footer Area -->
<footer class="footer-area section-gap">
    <div class="container">
        <div class="row">
            <div class="col-lg-6 col-md-8 col-sm-8">
                <div class="single-footer-widget">
                    <p class="footer-text">
                        <!-- Link back to Colorlib can't be removed.
                        Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | This template is made with
                        <i class="fa fa-heart-o" aria-hidden="true"></i> by
                        <a href="https://colorlib.com" target="_blank">Colorlib</a>
                        <!-- Link back to Colorlib can't be removed.
                        Template is licensed under CC BY 3.0. --></p>
                </div>
            </div>

            <div class="col-lg-6 col-md-8 col-sm-8 social-widget">
                <div class="single-footer-widget">
                    <div class="footer-social d-flex align-items-center"
                         style="float: right">
                        Let us be social&nbsp;&nbsp;
                        <a href="https://www.facebook.com/salmuz" target="_blank">
                            <i class="fa fa-facebook"></i></a>
                        <a href="https://twitter.com/salmuz" target="_blank">
                            <i class="fa fa-twitter"></i></a>
                        <a href="https://www.linkedin.com/in/ycarranza/" target="_blank">
                            <i class="fa fa-linkedin"></i></a>
                        <a href="https://github.com/salmuz" target="_blank">
                            <i class="fa fa-github"></i></a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</footer>
<!-- End footer Area -->

<script src="js/vendor/jquery-2.2.4.min.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/vendor/bootstrap.min.js"></script>

<script src="js/easing.min.js"></script>
<script src="js/hoverIntent.js"></script>
<script src="js/superfish.min.js"></script>
<script src="js/jquery.ajaxchimp.min.js"></script>
<script src="js/jquery.magnific-popup.min.js"></script>
<script src="js/jquery.tabs.min.js"></script>
<script src="js/jquery.nice-select.min.js"></script>
<script src="js/isotope.pkgd.min.js"></script>
<script src="js/waypoints.min.js"></script>
<script src="js/jquery.counterup.min.js"></script>
<script src="js/simple-skillbar.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/mail-script.js"></script>
<script src="js/main.js"></script>
</body>
</html>
